{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSCI 552 PS 1 - Used Car Dataset\n",
    "\n",
    "## Duplicate - scales the target variable `price` in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## data preparation and analysis\n",
    "import pandas as pd \n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import scipy as sp \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## modeling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LassoLars\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import custom function to get feature names\n",
    "from helper import get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9997, 14)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'../data/used_car_dataset.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>transmission</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21978.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>like new</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>80813.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>SUV</td>\n",
       "      <td>black</td>\n",
       "      <td>138</td>\n",
       "      <td>2.472286</td>\n",
       "      <td>0.059031</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4185.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>201800.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>SUV</td>\n",
       "      <td>white</td>\n",
       "      <td>415</td>\n",
       "      <td>2.285245</td>\n",
       "      <td>0.046328</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7693.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>pickup</td>\n",
       "      <td>white</td>\n",
       "      <td>535</td>\n",
       "      <td>1.861461</td>\n",
       "      <td>0.158554</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price    year manufacturer  condition    cylinders fuel  odometer  \\\n",
       "0  21978.0  2016.0         ford   like new  6 cylinders  gas   80813.0   \n",
       "1   4185.0  2008.0         ford       good  8 cylinders  gas  201800.0   \n",
       "2   7693.0  2002.0         ford  excellent  6 cylinders  gas  145000.0   \n",
       "\n",
       "  transmission    type paint_color   F1        F2        F3 F4  \n",
       "0    automatic     SUV       black  138  2.472286  0.059031  b  \n",
       "1    automatic     SUV       white  415  2.285245  0.046328  c  \n",
       "2    automatic  pickup       white  535  1.861461  0.158554  b  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 14 attributes\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA / cleaning / transforming step\n",
    "Your CEO said: “The dataset describes conditions of various used cars and their current prices.\n",
    "I would like to learn **what drives prices of used cars**. \n",
    "\n",
    "1. Look at the dataset and find the **main factors**\n",
    "that affect the **value** of a car – and then explain it to me. \n",
    "\n",
    "2. Additionally, assess the **impact** of some special modifications (denoted by **F1, F2, F3 and F4** in your dataset) on the price. This would help us to understand, **if we should make the modifications before selling a car or not**. I would\n",
    "like to see the report, describing your main findings, on my desk, on Thursday, February 11,\n",
    "2021 at 10 A.M. “\n",
    "\n",
    "Hint: You are asked to **find general trends** in the data. Report whatever you think is the most important. Your CEO\n",
    "doesn’t want to see a list that is 20-times long. She would like to learn just about some general trends. To give you\n",
    "an example, one general trend could be “The price decrease with the age of the car. Holding all other factors\n",
    "constant, with each year, the price of a car decreases by \\$570. However, these dynamics are not constant. Value of\n",
    "younger cars decreases faster than the value of an old car. For example, the value of cars that are less than 5 years\n",
    "old, decreases nearly $2,500 per year.” (This is just an example; your numbers might be different). Your second\n",
    "task you have to check both, the **impact** and the **statistical significance** of the **F1-F4 attributes** for making the price predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "num_cols_no_price = ['year', 'odometer', 'F1', 'F2', 'F3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9997, 14) (9603, 14)\n"
     ]
    }
   ],
   "source": [
    "## Normalize data\n",
    "min_max_scaler = MinMaxScaler()\n",
    "nums_scaled = pd.DataFrame(min_max_scaler.fit_transform(df[num_cols]))\n",
    "nums_scaled.columns = num_cols\n",
    "\n",
    "## Outlier removal: get indicies of outlier locations\n",
    "outlier_locs = []\n",
    "for col in num_cols:\n",
    "    curr = df[col]\n",
    "    mean, std = np.mean(curr), np.std(curr)\n",
    "    cut_off = std * 3\n",
    "    lower, upper = mean - cut_off, mean + cut_off\n",
    "    # print(col, lower, upper)  \n",
    "    for idx, val in curr.items():\n",
    "        if val < lower or val > upper:\n",
    "            outlier_locs.append(idx)\n",
    "outliers = list(set(outlier_locs))\n",
    "## df2 is just df without the outliers\n",
    "df2 = df.drop(df.index[outliers])\n",
    "nums_scaled2 = nums_scaled.drop(nums_scaled.index[outliers])\n",
    "print(df.shape, df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9603, 30)\n",
      "(9603, 22)\n"
     ]
    }
   ],
   "source": [
    "## TRANSFORM STEP (After outlier removal)\n",
    "## Transforms the dataset to prep for model\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('minmaxscaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "## normal pipeline for Regularized Regression only\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"numerical\", num_pipeline, num_cols),\n",
    "    (\"categorical\", OneHotEncoder(), cat_cols)\n",
    "#     (\"categorical\", OneHotEncoder(drop='first'), cat_cols)\n",
    "\n",
    "])\n",
    "\n",
    "## drop first dummy vars for Lin Reg\n",
    "full_pipeline_drop = ColumnTransformer([\n",
    "    (\"numerical\", num_pipeline, num_cols),\n",
    "    # (\"categorical\", OneHotEncoder(), cat_cols)\n",
    "    (\"categorical\", OneHotEncoder(drop='first'), cat_cols)\n",
    "])\n",
    "\n",
    "arr_nodrop = full_pipeline.fit_transform(df2)  ## did NOT drop any dummy vars\n",
    "print(arr_nodrop.shape)\n",
    "arr_cleaned = full_pipeline_drop.fit_transform(df2)  ### has dropped dummy vars\n",
    "print(arr_cleaned.shape) # After outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_nodrop = get_feature_names(full_pipeline)\n",
    "feature_names_drop = get_feature_names(full_pipeline_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect multicollinearity btwn predictors\n",
    "## using VIF (variance inflation factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "[64.11785621953098, 50.55235872591882, 9.083711074645462, 6.194821468142453, 6.173382559100857, 4.030180656853217, 3.0490687258741267, 2.71499730104226, 2.565002885268519, 2.142763685164924, 2.0647203768171156, 2.043027649593444, 2.0075014859211633, 1.956765404568849, 1.8052524380294417, 1.7560040959372858, 1.7516771588840268, 1.633930286772232, 1.466875075690039, 1.2810032117784544, 1.1744504335039603, 1.1625796583635861]\n"
     ]
    }
   ],
   "source": [
    "vifs = [variance_inflation_factor(arr_cleaned, i) for i in range(arr_cleaned.shape[1])]\n",
    "print(len(vifs))\n",
    "## NOTE: any VIF > 4 needs investigation for possible multicollinearity!\n",
    "print(sorted(vifs)[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## using OLS Linear Regression (df with dropped dummy vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9603, 21) (9603,)\n",
      "(7682, 21) (1921, 21)\n"
     ]
    }
   ],
   "source": [
    "## Split in train/test/valid\n",
    "X = arr_cleaned[:,1:]\n",
    "y = arr_cleaned[:,0]\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2021)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.019652955905571857\n",
      "Coefficient of determination R^2: 0.56641872428702\n"
     ]
    }
   ],
   "source": [
    "# ## Linear Reg Model - TEST (use sklearn)\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "# print('Coefficients: \\n', lin_reg.coef_)\n",
    "print(f'Mean squared error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Coefficient of determination R^2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   565.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 Feb 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:40:53</td>     <th>  Log-Likelihood:    </th> <td>  4601.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  7682</td>      <th>  AIC:               </th> <td>  -9158.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  7660</td>      <th>  BIC:               </th> <td>  -9006.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    21</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                       <td>   -0.2402</td> <td>    0.013</td> <td>  -17.934</td> <td> 0.000</td> <td>   -0.266</td> <td>   -0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numerical__year</th>             <td>    0.6521</td> <td>    0.018</td> <td>   36.555</td> <td> 0.000</td> <td>    0.617</td> <td>    0.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numerical__odometer</th>         <td>   -0.4495</td> <td>    0.014</td> <td>  -32.604</td> <td> 0.000</td> <td>   -0.477</td> <td>   -0.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numerical__F1</th>               <td>    0.0484</td> <td>    0.008</td> <td>    5.827</td> <td> 0.000</td> <td>    0.032</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numerical__F2</th>               <td>   -0.0058</td> <td>    0.018</td> <td>   -0.321</td> <td> 0.748</td> <td>   -0.041</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numerical__F3</th>               <td>    0.1178</td> <td>    0.009</td> <td>   12.756</td> <td> 0.000</td> <td>    0.100</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x0_subaru</th>      <td>    0.0590</td> <td>    0.006</td> <td>   10.117</td> <td> 0.000</td> <td>    0.048</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x1_fair</th>        <td>   -0.0274</td> <td>    0.009</td> <td>   -3.053</td> <td> 0.002</td> <td>   -0.045</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x1_good</th>        <td>   -0.0057</td> <td>    0.003</td> <td>   -1.666</td> <td> 0.096</td> <td>   -0.012</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x1_like new</th>    <td>    0.0248</td> <td>    0.005</td> <td>    4.829</td> <td> 0.000</td> <td>    0.015</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x2_6 cylinders</th> <td>    0.0811</td> <td>    0.005</td> <td>   17.889</td> <td> 0.000</td> <td>    0.072</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x2_8 cylinders</th> <td>    0.1074</td> <td>    0.006</td> <td>   19.077</td> <td> 0.000</td> <td>    0.096</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x4_manual</th>      <td>    0.0610</td> <td>    0.008</td> <td>    7.782</td> <td> 0.000</td> <td>    0.046</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x5_pickup</th>      <td>    0.1172</td> <td>    0.005</td> <td>   22.916</td> <td> 0.000</td> <td>    0.107</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x5_sedan</th>       <td>   -0.0546</td> <td>    0.004</td> <td>  -12.828</td> <td> 0.000</td> <td>   -0.063</td> <td>   -0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x5_truck</th>       <td>    0.1018</td> <td>    0.005</td> <td>   21.544</td> <td> 0.000</td> <td>    0.093</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x6_blue</th>        <td>   -0.0130</td> <td>    0.005</td> <td>   -2.390</td> <td> 0.017</td> <td>   -0.024</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x6_red</th>         <td>   -0.0029</td> <td>    0.005</td> <td>   -0.564</td> <td> 0.573</td> <td>   -0.013</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x6_silver</th>      <td>   -0.0169</td> <td>    0.005</td> <td>   -3.290</td> <td> 0.001</td> <td>   -0.027</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x6_white</th>       <td>   -0.0288</td> <td>    0.004</td> <td>   -6.608</td> <td> 0.000</td> <td>   -0.037</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x7_b</th>           <td>    0.0013</td> <td>    0.004</td> <td>    0.342</td> <td> 0.733</td> <td>   -0.006</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x7_c</th>           <td>   -0.0054</td> <td>    0.004</td> <td>   -1.441</td> <td> 0.150</td> <td>   -0.013</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1015.318</td> <th>  Durbin-Watson:     </th> <td>   1.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4702.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.567</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 6.661</td>  <th>  Cond. No.          </th> <td>    28.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.608\n",
       "Model:                            OLS   Adj. R-squared:                  0.607\n",
       "Method:                 Least Squares   F-statistic:                     565.9\n",
       "Date:                Sat, 06 Feb 2021   Prob (F-statistic):               0.00\n",
       "Time:                        16:40:53   Log-Likelihood:                 4601.2\n",
       "No. Observations:                7682   AIC:                            -9158.\n",
       "Df Residuals:                    7660   BIC:                            -9006.\n",
       "Df Model:                          21                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "const                          -0.2402      0.013    -17.934      0.000      -0.266      -0.214\n",
       "numerical__year                 0.6521      0.018     36.555      0.000       0.617       0.687\n",
       "numerical__odometer            -0.4495      0.014    -32.604      0.000      -0.477      -0.422\n",
       "numerical__F1                   0.0484      0.008      5.827      0.000       0.032       0.065\n",
       "numerical__F2                  -0.0058      0.018     -0.321      0.748      -0.041       0.029\n",
       "numerical__F3                   0.1178      0.009     12.756      0.000       0.100       0.136\n",
       "categorical__x0_subaru          0.0590      0.006     10.117      0.000       0.048       0.070\n",
       "categorical__x1_fair           -0.0274      0.009     -3.053      0.002      -0.045      -0.010\n",
       "categorical__x1_good           -0.0057      0.003     -1.666      0.096      -0.012       0.001\n",
       "categorical__x1_like new        0.0248      0.005      4.829      0.000       0.015       0.035\n",
       "categorical__x2_6 cylinders     0.0811      0.005     17.889      0.000       0.072       0.090\n",
       "categorical__x2_8 cylinders     0.1074      0.006     19.077      0.000       0.096       0.118\n",
       "categorical__x4_manual          0.0610      0.008      7.782      0.000       0.046       0.076\n",
       "categorical__x5_pickup          0.1172      0.005     22.916      0.000       0.107       0.127\n",
       "categorical__x5_sedan          -0.0546      0.004    -12.828      0.000      -0.063      -0.046\n",
       "categorical__x5_truck           0.1018      0.005     21.544      0.000       0.093       0.111\n",
       "categorical__x6_blue           -0.0130      0.005     -2.390      0.017      -0.024      -0.002\n",
       "categorical__x6_red            -0.0029      0.005     -0.564      0.573      -0.013       0.007\n",
       "categorical__x6_silver         -0.0169      0.005     -3.290      0.001      -0.027      -0.007\n",
       "categorical__x6_white          -0.0288      0.004     -6.608      0.000      -0.037      -0.020\n",
       "categorical__x7_b               0.0013      0.004      0.342      0.733      -0.006       0.008\n",
       "categorical__x7_c              -0.0054      0.004     -1.441      0.150      -0.013       0.002\n",
       "==============================================================================\n",
       "Omnibus:                     1015.318   Durbin-Watson:                   1.997\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4702.931\n",
       "Skew:                          -0.567   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.661   Cond. No.                         28.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Linear Reg Model - TEST (use sm)\n",
    "X_train_df = pd.DataFrame(X_train, columns=feature_names_drop[1:])\n",
    "# X_train_df.head()\n",
    "X0_train = sm.add_constant(X_train_df)\n",
    "model = sm.OLS(y_train, X0_train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numerical__year                33810.524067\n",
       "numerical__F3                   6105.701887\n",
       "categorical__x5_pickup          6075.246943\n",
       "categorical__x2_8 cylinders     5567.089821\n",
       "categorical__x5_truck           5280.219569\n",
       "categorical__x2_6 cylinders     4205.534392\n",
       "categorical__x4_manual          3160.783363\n",
       "categorical__x0_subaru          3061.093317\n",
       "numerical__F1                   2511.810400\n",
       "categorical__x1_like new        1286.755971\n",
       "categorical__x7_b                 65.354245\n",
       "categorical__x6_red             -149.398228\n",
       "categorical__x7_c               -280.921173\n",
       "categorical__x1_good            -297.140980\n",
       "numerical__F2                   -299.121251\n",
       "categorical__x6_blue            -675.152826\n",
       "categorical__x6_silver          -873.738601\n",
       "categorical__x1_fair           -1418.334273\n",
       "categorical__x6_white          -1491.573170\n",
       "categorical__x5_sedan          -2833.173716\n",
       "const                         -12456.078559\n",
       "numerical__odometer           -23308.210957\n",
       "dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = model.params\n",
    "params.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By manually checking parameter magnitudes, it seems **year, F3, pickup, 8 cylinders** are most significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot check / Compare models\n",
    "#### try diff models compare results using kfold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict of standard models to evaluate\n",
    "def define_models(models=dict()):\n",
    "    models['linear_reg'] = LinearRegression()\n",
    "    alpha = [round(x, 2) for x in np.linspace(0,1,11)]\n",
    "    for a in alpha:\n",
    "        models['lasso_reg_'+str(a)] = Lasso(alpha=a)\n",
    "        models['ridge_reg_'+str(a)] = Ridge(alpha=a)\n",
    "        models['en_reg_'+str(a)] = ElasticNet(alpha=a)\n",
    "    return models\n",
    " \n",
    "# evaluate a single model\n",
    "def evaluate_model(X, y, model, folds, metric):\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(estimator=model, X=X, y=y, scoring=metric, cv=folds, n_jobs=1)\n",
    "\treturn scores\n",
    "\n",
    "## see more metrics on sklearn docs\n",
    "## https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "## e.g. using RMSE (LOWER (i.e. more negative vals) = better fit)\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X, y, models, folds=5, metric='neg_root_mean_squared_error'):   \n",
    "    results = dict()\n",
    "    print(f\"Using {metric} metric for scores below:\\n\")\n",
    "    for name, model in models.items():\n",
    "        # scores = robust_evaluate_model(X, y, model, folds, metric)\n",
    "        scores = evaluate_model(X, y, model, folds, metric)\n",
    "        if scores is not None:\n",
    "            results[name] = scores\n",
    "            mean_score, std_score = np.mean(scores), np.std(scores)\n",
    "            print(f'{name}: Mean:{mean_score:.3f}, St.Dev:{std_score:.3f}')\n",
    "        else:\n",
    "            print(f'{name}: error')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9603, 29) (9603,)\n",
      "(7682, 29) (1921, 29)\n",
      "Using neg_root_mean_squared_error metric for scores below:\n",
      "\n",
      "linear_reg: Mean:-0.135, St.Dev:0.003\n",
      "lasso_reg_0.0: Mean:-0.135, St.Dev:0.002\n",
      "ridge_reg_0.0: Mean:-0.136, St.Dev:0.002\n",
      "en_reg_0.0: Mean:-0.135, St.Dev:0.002\n",
      "lasso_reg_0.1: Mean:-0.212, St.Dev:0.004\n",
      "ridge_reg_0.1: Mean:-0.135, St.Dev:0.002\n",
      "en_reg_0.1: Mean:-0.212, St.Dev:0.004\n",
      "lasso_reg_0.2: Mean:-0.212, St.Dev:0.004\n",
      "ridge_reg_0.2: Mean:-0.135, St.Dev:0.002\n",
      "en_reg_0.2: Mean:-0.212, St.Dev:0.004\n",
      "lasso_reg_0.3: Mean:-0.212, St.Dev:0.004\n",
      "ridge_reg_0.3: Mean:-0.135, St.Dev:0.002\n",
      "en_reg_0.3: Mean:-0.212, St.Dev:0.004\n",
      "lasso_reg_0.4: Mean:-0.212, St.Dev:0.004\n",
      "ridge_reg_0.4: Mean:-0.135, St.Dev:0.002\n",
      "en_reg_0.4: Mean:-0.212, St.Dev:0.004\n",
      "lasso_reg_0.5: Mean:-0.212, St.Dev:0.004\n",
      "ridge_reg_0.5: Mean:-0.135, St.Dev:0.002\n",
      "en_reg_0.5: Mean:-0.212, St.Dev:0.004\n",
      "lasso_reg_0.6: Mean:-0.212, St.Dev:0.004\n",
      "ridge_reg_0.6: Mean:-0.135, St.Dev:0.002\n",
      "en_reg_0.6: Mean:-0.212, St.Dev:0.004\n",
      "lasso_reg_0.7: Mean:-0.212, St.Dev:0.004\n",
      "ridge_reg_0.7: Mean:-0.135, St.Dev:0.002\n",
      "en_reg_0.7: Mean:-0.212, St.Dev:0.004\n",
      "lasso_reg_0.8: Mean:-0.212, St.Dev:0.004\n",
      "ridge_reg_0.8: Mean:-0.135, St.Dev:0.002\n",
      "en_reg_0.8: Mean:-0.212, St.Dev:0.004\n",
      "lasso_reg_0.9: Mean:-0.212, St.Dev:0.004\n",
      "ridge_reg_0.9: Mean:-0.135, St.Dev:0.002\n",
      "en_reg_0.9: Mean:-0.212, St.Dev:0.004\n",
      "lasso_reg_1.0: Mean:-0.212, St.Dev:0.004\n",
      "ridge_reg_1.0: Mean:-0.135, St.Dev:0.002\n",
      "en_reg_1.0: Mean:-0.212, St.Dev:0.004\n"
     ]
    }
   ],
   "source": [
    "## Split in train/test/valid\n",
    "X = arr_nodrop[:,1:]\n",
    "y = arr_nodrop[:,0]\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2021)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "models = define_models() \n",
    "results = evaluate_models(X, y, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lasso_reg_0.1', -0.2124),\n",
       " ('en_reg_0.1', -0.2124),\n",
       " ('lasso_reg_0.2', -0.2124),\n",
       " ('en_reg_0.2', -0.2124),\n",
       " ('lasso_reg_0.3', -0.2124),\n",
       " ('en_reg_0.3', -0.2124),\n",
       " ('lasso_reg_0.4', -0.2124),\n",
       " ('en_reg_0.4', -0.2124),\n",
       " ('lasso_reg_0.5', -0.2124),\n",
       " ('en_reg_0.5', -0.2124),\n",
       " ('lasso_reg_0.6', -0.2124),\n",
       " ('en_reg_0.6', -0.2124),\n",
       " ('lasso_reg_0.7', -0.2124),\n",
       " ('en_reg_0.7', -0.2124),\n",
       " ('lasso_reg_0.8', -0.2124),\n",
       " ('en_reg_0.8', -0.2124),\n",
       " ('lasso_reg_0.9', -0.2124),\n",
       " ('en_reg_0.9', -0.2124),\n",
       " ('lasso_reg_1.0', -0.2124),\n",
       " ('en_reg_1.0', -0.2124),\n",
       " ('ridge_reg_0.0', -0.1361),\n",
       " ('linear_reg', -0.1355),\n",
       " ('lasso_reg_0.0', -0.1346),\n",
       " ('en_reg_0.0', -0.1346),\n",
       " ('ridge_reg_0.1', -0.1346),\n",
       " ('ridge_reg_0.2', -0.1346),\n",
       " ('ridge_reg_0.3', -0.1346),\n",
       " ('ridge_reg_0.4', -0.1346),\n",
       " ('ridge_reg_0.5', -0.1346),\n",
       " ('ridge_reg_0.6', -0.1346),\n",
       " ('ridge_reg_0.7', -0.1346),\n",
       " ('ridge_reg_0.8', -0.1346),\n",
       " ('ridge_reg_0.9', -0.1346),\n",
       " ('ridge_reg_1.0', -0.1346)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_results = {name: np.round(np.mean(arr), 4) for name, arr in results.items()}\n",
    "## sort results with 'best' models first (having lowest error scores)\n",
    "sorted(mean_results.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Lasso and EN at diff alpha values do equally well, better than ridge or plain lin reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and plot the top n results\n",
    "def summarize_results(results, maximize=False, top_n=10):\n",
    "    # check for no results\n",
    "    if len(results) == 0:\n",
    "        print('no results')\n",
    "        return\n",
    "    # determine how many results to summarize\n",
    "    n = min(top_n, len(results))\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_scores = [(k, np.mean(v)) for k, v in results.items()]\n",
    "    # sort tuples by mean score\n",
    "    mean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "    # reverse for descending order (e.g. for accuracy)\n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "    # retrieve the top n for summarization\n",
    "    names = [x[0] for x in mean_scores[:n]]\n",
    "    scores = [results[x[0]] for x in mean_scores[:n]]\n",
    "    # print the top n\n",
    "    print()\n",
    "    for i in range(n):\n",
    "        name = names[i]\n",
    "        mean_score, std_score = np.mean(results[name]), np.std(results[name])\n",
    "        print('Rank=%d, Name=%s, Score=%.3f (+/- %.3f)' %\n",
    "              (i+1, name, mean_score, std_score))\n",
    "    # boxplot for the top n\n",
    "    plt.boxplot(scores, labels=names)\n",
    "    _, labels = plt.xticks()\n",
    "    plt.setp(labels, rotation=90)\n",
    "    # pyplot.savefig('spotcheck.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rank=1, Name=lasso_reg_0.1, Score=-0.212 (+/- 0.004)\n",
      "Rank=2, Name=en_reg_0.1, Score=-0.212 (+/- 0.004)\n",
      "Rank=3, Name=lasso_reg_0.2, Score=-0.212 (+/- 0.004)\n",
      "Rank=4, Name=en_reg_0.2, Score=-0.212 (+/- 0.004)\n",
      "Rank=5, Name=lasso_reg_0.3, Score=-0.212 (+/- 0.004)\n",
      "Rank=6, Name=en_reg_0.3, Score=-0.212 (+/- 0.004)\n",
      "Rank=7, Name=lasso_reg_0.4, Score=-0.212 (+/- 0.004)\n",
      "Rank=8, Name=en_reg_0.4, Score=-0.212 (+/- 0.004)\n",
      "Rank=9, Name=lasso_reg_0.5, Score=-0.212 (+/- 0.004)\n",
      "Rank=10, Name=en_reg_0.5, Score=-0.212 (+/- 0.004)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean squared error: 0.15311137228120397\n",
      "MASE: 0.11059070385584574\n",
      "Coefficient of determination R^2: 0.4828011661759263\n"
     ]
    }
   ],
   "source": [
    "## EN model\n",
    "en_reg = ElasticNet(alpha=0.01)\n",
    "en_reg.fit(X_train, y_train)\n",
    "y_pred_en = en_reg.predict(X_test)\n",
    "# print('Coefficients: \\n', en_reg.coef_)\n",
    "print(f'Root Mean squared error: {mean_squared_error(y_test, y_pred_en, squared=False)}')\n",
    "print(f'MASE: {mean_absolute_error(y_test, y_pred_en)}')\n",
    "print(f'Coefficient of determination R^2: {r2_score(y_test, y_pred_en)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.045375315746765885\n",
      "Coefficient of determination R^2: -0.0010650500561206755\n"
     ]
    }
   ],
   "source": [
    "# Lasso model\n",
    "lasso_reg = Lasso(alpha=1.0)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_reg.predict(X_test)\n",
    "# print('Coefficients: \\n', lasso_reg.coef_)\n",
    "print(f'Mean squared error: {mean_squared_error(y_test, y_pred_lasso)}')\n",
    "print(f'Coefficient of determination R^2: {r2_score(y_test, y_pred_lasso)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train, columns=feature_names_nodrop[1:])\n",
    "# X_train_df.head()\n",
    "X0_train = sm.add_constant(X_train_df)\n",
    "model = sm.regression.linear_model.OLS(y_train, X0_train)\n",
    "res = model.fit_regularized(method='sqrt_lasso', alpha=0.1, L1_wt=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numerical__year                0.651839\n",
       "numerical__odometer           -0.449480\n",
       "numerical__F1                  0.048428\n",
       "numerical__F2                 -0.005495\n",
       "numerical__F3                  0.117700\n",
       "categorical__x0_ford          -0.047372\n",
       "categorical__x0_subaru         0.011644\n",
       "categorical__x1_excellent      0.002187\n",
       "categorical__x1_fair          -0.025140\n",
       "categorical__x1_good          -0.003541\n",
       "categorical__x1_like new       0.026995\n",
       "categorical__x2_4 cylinders   -0.081095\n",
       "categorical__x2_6 cylinders    0.000003\n",
       "categorical__x2_8 cylinders    0.026254\n",
       "categorical__x3_gas           -0.000010\n",
       "categorical__x4_automatic     -0.049027\n",
       "categorical__x4_manual         0.011896\n",
       "categorical__x5_SUV           -0.077874\n",
       "categorical__x5_pickup         0.039287\n",
       "categorical__x5_sedan         -0.132515\n",
       "categorical__x5_truck          0.023952\n",
       "categorical__x6_black          0.013025\n",
       "categorical__x6_blue           0.000013\n",
       "categorical__x6_red            0.010143\n",
       "categorical__x6_silver        -0.003814\n",
       "categorical__x6_white         -0.015730\n",
       "categorical__x7_a             -0.000030\n",
       "categorical__x7_b              0.001228\n",
       "categorical__x7_c             -0.005444\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Senior Developer took you aside and said: “My task is to deploy your model to\n",
    "production. But I cannot deploy a paper-report. I need your code. However, remember that I am\n",
    "not a Data Scientist list you. I have a different expertise. I will read your code, but you should\n",
    "make sure that I can follow and understand it – and that I know how to use it.”\n",
    "\n",
    "\n",
    "Hint: In the ideal case, people should be able to take your code, run it and recreate all your results. In a less ideal case, it should be a **demonstration of typical run**. The code should **demonstrate your approach end-to-end**. People should just specify the path to the dataset, run it and see final results. Another name for this is a technical demo. At your future work, you might be quite often asked to demo your results. People will expect you to present an end-to- end example where you read the raw data, train your model and evaluate the results of the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: BEFORE SUBMITTING CODE: \n",
    "### remember to remove all comments, change code structure so you didn't copy anyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
