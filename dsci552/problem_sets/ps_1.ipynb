{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSCI 552 PS 1 - Used Car Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## data preparation and analysis\n",
    "import pandas as pd \n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import scipy as sp \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## modeling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LassoLars\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import custom function to get feature names\n",
    "from helper import get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9997, 14)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'../data/used_car_dataset.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>transmission</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21978.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>like new</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>80813.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>SUV</td>\n",
       "      <td>black</td>\n",
       "      <td>138</td>\n",
       "      <td>2.472286</td>\n",
       "      <td>0.059031</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4185.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>201800.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>SUV</td>\n",
       "      <td>white</td>\n",
       "      <td>415</td>\n",
       "      <td>2.285245</td>\n",
       "      <td>0.046328</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7693.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>pickup</td>\n",
       "      <td>white</td>\n",
       "      <td>535</td>\n",
       "      <td>1.861461</td>\n",
       "      <td>0.158554</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price    year manufacturer  condition    cylinders fuel  odometer  \\\n",
       "0  21978.0  2016.0         ford   like new  6 cylinders  gas   80813.0   \n",
       "1   4185.0  2008.0         ford       good  8 cylinders  gas  201800.0   \n",
       "2   7693.0  2002.0         ford  excellent  6 cylinders  gas  145000.0   \n",
       "\n",
       "  transmission    type paint_color   F1        F2        F3 F4  \n",
       "0    automatic     SUV       black  138  2.472286  0.059031  b  \n",
       "1    automatic     SUV       white  415  2.285245  0.046328  c  \n",
       "2    automatic  pickup       white  535  1.861461  0.158554  b  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 14 attributes\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA / cleaning / transforming step\n",
    "Your CEO said: “The dataset describes conditions of various used cars and their current prices.\n",
    "I would like to learn **what drives prices of used cars**. \n",
    "\n",
    "1. Look at the dataset and find the **main factors**\n",
    "that affect the **value** of a car – and then explain it to me. \n",
    "\n",
    "2. Additionally, assess the **impact** of some special modifications (denoted by **F1, F2, F3 and F4** in your dataset) on the price. This would help us to understand, **if we should make the modifications before selling a car or not**. I would\n",
    "like to see the report, describing your main findings, on my desk, on Thursday, February 11,\n",
    "2021 at 10 A.M. “\n",
    "\n",
    "Hint: You are asked to **find general trends** in the data. Report whatever you think is the most important. Your CEO\n",
    "doesn’t want to see a list that is 20-times long. She would like to learn just about some general trends. To give you\n",
    "an example, one general trend could be “The price decrease with the age of the car. Holding all other factors\n",
    "constant, with each year, the price of a car decreases by \\$570. However, these dynamics are not constant. Value of\n",
    "younger cars decreases faster than the value of an old car. For example, the value of cars that are less than 5 years\n",
    "old, decreases nearly $2,500 per year.” (This is just an example; your numbers might be different). Your second\n",
    "task you have to check both, the **impact** and the **statistical significance** of the **F1-F4 attributes** for making the price predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE:\n",
    "## Due to skewed datasets, we should clean data by:\n",
    "## fill missing vals (median imputation)\n",
    "## scale the datasets (minmaxscaler)\n",
    "## remove outliers\n",
    "## and one-hot encoding for categorical vars (to prep for model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "num_cols_no_price = ['year', 'odometer', 'F1', 'F2', 'F3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9997, 14) (9603, 14)\n"
     ]
    }
   ],
   "source": [
    "## Normalize data\n",
    "min_max_scaler = MinMaxScaler()\n",
    "nums_scaled = pd.DataFrame(min_max_scaler.fit_transform(df[num_cols]))\n",
    "nums_scaled.columns = num_cols\n",
    "\n",
    "## Outlier removal: get indicies of outlier locations\n",
    "outlier_locs = []\n",
    "for col in num_cols:\n",
    "    curr = df[col]\n",
    "    mean, std = np.mean(curr), np.std(curr)\n",
    "    cut_off = std * 3\n",
    "    lower, upper = mean - cut_off, mean + cut_off\n",
    "    # print(col, lower, upper)  \n",
    "    for idx, val in curr.items():\n",
    "        if val < lower or val > upper:\n",
    "            outlier_locs.append(idx)\n",
    "outliers = list(set(outlier_locs))\n",
    "## df2 is just df without the outliers\n",
    "df2 = df.drop(df.index[outliers])\n",
    "nums_scaled2 = nums_scaled.drop(nums_scaled.index[outliers])\n",
    "print(df.shape, df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## plot data\n",
    "# df2.hist(bins=50, figsize=(16,8))\n",
    "# plt.savefig('images/hist_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## View correlations btwn features\n",
    "# # focus on effect on PRICE\n",
    "# plt.figure(figsize=(10,6))\n",
    "# sns.heatmap(df2.corr(), annot=True, cmap=\"hot_r\")\n",
    "# # plt.savefig('images/heatmap_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## boxplots for numerical vars\n",
    "# fig, axes = plt.subplots(2, 3, sharex = False, figsize=(16,8))\n",
    "# fig.suptitle('Boxplots')\n",
    "\n",
    "# for i, var in enumerate(num_cols):\n",
    "#     if i < 3:\n",
    "#         row = 0\n",
    "#     elif i >= 3: \n",
    "#         row = 1\n",
    "#     col = i % 3\n",
    "#     sns.boxplot(ax=axes[row,col], data=df2, x=var)\n",
    "# plt.savefig('images/boxplots_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Categorical vars and PRICE\n",
    "# fig, axes = plt.subplots(2, 4, sharex = False, figsize=(16,8))\n",
    "# fig.suptitle('Categorical Vars and Price')\n",
    "# for i, var in enumerate(cat_cols):\n",
    "#     if i < 4:\n",
    "#         row = 0\n",
    "#     elif i >= 4: \n",
    "#         row = 1\n",
    "#     col = i % 4\n",
    "#     axes[row][col] = sns.stripplot(x=var, y='price', data=df2, ax=axes[row][col])\n",
    "# fig.tight_layout()\n",
    "# plt.savefig('images/catplots_and_price_1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: write about trends btwn price and various features (how they correlate as they go up or down) in the report \n",
    "From results of lin reg (using sm further on down the notebook): **year, type, cylinders, and F3** are most significant with price. So I will look specifically at these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.describe()\n",
    "# # df2['price'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.displot(data=df2, x='price', kde=True)\n",
    "# g.fig.subplots_adjust(top=.95)\n",
    "# g.ax.set_title(\"Distribution of Price\")\n",
    "# # plt.savefig('../images/PS_1/price_histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## How does price vary across types?\n",
    "# sns.boxplot(x='type', y='price', data=df2)\n",
    "# plt.title(\"Price by Type\")\n",
    "# # plt.savefig('../images/PS_1/price_type_boxplot.png')|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greater variability for pickup and truck types and they have similar medians. SUV and sedan have lower variability and more concentration of higher-priced outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## How does price vary across num. of cylinders?\n",
    "# sns.boxplot(x='cylinders', y='price', data=df2)\n",
    "# plt.title(\"Price by Cylinders\")\n",
    "# # plt.savefig('../images/PS_1/price_cylinders_boxplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greater variability for 6 and 8 cylinder cars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,6))\n",
    "# plt.title(\"Price By Year\")\n",
    "# sns.scatterplot(x='year', y='price', hue='cylinders', data=df2)\n",
    "# # plt.scatter(x=df2['year'], y=df2['price'])\n",
    "# # plt.savefig('../images/PS_1/price_by_year_cylinders.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,6))\n",
    "# plt.title(\"Price By Year\")\n",
    "# sns.scatterplot(x='year', y='price', hue='type', data=df2)\n",
    "# # plt.savefig('../images/PS_1/price_by_year_type.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,8))\n",
    "# sns.scatterplot(x='F3', y='price', data=df2)\n",
    "# # plt.scatter(x=df2['year'], y=df2['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Modeling , Tuning, and Evaluation \n",
    "Your Technical Manager said: “I would like you to propose a **predictive model**, that can be used to determine price of a used car. The problem is that the state-law demands that this model be easily interpretable. It means that we are restricted to use simple methods like **Linear Regression, Ridge Regression, LASSO and Elastic Net**. Additionally, we need to know how **accurate** the model is. You must choose the best model and report its **root mean square error**. Describe everything in your report and I will study it carefully”.\n",
    "Hint: In the most typical approach, you need to build three datasets: **a training set, a validation set and a test set**. You will use **validation set** (for tuning model hyperparameters) to determine the best model; the test set to estimate model accuracy. In your report you should describe how you trained the models, how you selected the best one and how you tested its performance at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS regression for CEO part\n",
    "## Transformation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>transmission</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>like new</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>80813.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>SUV</td>\n",
       "      <td>black</td>\n",
       "      <td>138</td>\n",
       "      <td>2.472286</td>\n",
       "      <td>0.059031</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>201800.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>SUV</td>\n",
       "      <td>white</td>\n",
       "      <td>415</td>\n",
       "      <td>2.285245</td>\n",
       "      <td>0.046328</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>pickup</td>\n",
       "      <td>white</td>\n",
       "      <td>535</td>\n",
       "      <td>1.861461</td>\n",
       "      <td>0.158554</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>excellent</td>\n",
       "      <td>4 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>50103.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>sedan</td>\n",
       "      <td>white</td>\n",
       "      <td>3435</td>\n",
       "      <td>2.331671</td>\n",
       "      <td>0.213665</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>207663.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>truck</td>\n",
       "      <td>white</td>\n",
       "      <td>1212</td>\n",
       "      <td>2.061082</td>\n",
       "      <td>0.388724</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year manufacturer  condition    cylinders fuel  odometer transmission  \\\n",
       "0  2016.0         ford   like new  6 cylinders  gas   80813.0    automatic   \n",
       "1  2008.0         ford       good  8 cylinders  gas  201800.0    automatic   \n",
       "2  2002.0         ford  excellent  6 cylinders  gas  145000.0    automatic   \n",
       "3  2016.0         ford  excellent  4 cylinders  gas   50103.0    automatic   \n",
       "4  2005.0         ford       good  8 cylinders  gas  207663.0    automatic   \n",
       "\n",
       "     type paint_color    F1        F2        F3 F4  \n",
       "0     SUV       black   138  2.472286  0.059031  b  \n",
       "1     SUV       white   415  2.285245  0.046328  c  \n",
       "2  pickup       white   535  1.861461  0.158554  b  \n",
       "3   sedan       white  3435  2.331671  0.213665  c  \n",
       "4   truck       white  1212  2.061082  0.388724  b  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.drop(['price'],axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9603, 21)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Do Model WITHOUT scaling\n",
    "    to get coeff and p-values from sm\n",
    "\"\"\"\n",
    "## TRANSFORM STEP (After outlier removal)\n",
    "## Transforms the dataset to prep for model\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "## drop first dummy vars for Lin Reg\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"numerical\", num_pipeline, num_cols_no_price),\n",
    "    (\"categorical\", OneHotEncoder(drop='first'), cat_cols)\n",
    "])\n",
    "\n",
    "arr = full_pipeline.fit_transform(df3)  ### dropped dummy vars\n",
    "print(arr.shape) # After outlier removal\n",
    "feature_names = get_feature_names(full_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "[299.26406445266826, 249.98519659110258, 6.100689119014561, 4.261642179609693, 3.233789149309924, 2.7768443447454043, 2.434597928073263, 2.0947094867570377, 2.075663063670362, 2.042564447221222, 2.0146611451577114, 1.9759717879300158, 1.947545652635113, 1.839372519729242, 1.829295445789961, 1.8128542011234523, 1.6952636550763105, 1.4731098862391672, 1.2713370940472877, 1.1792243125126092, 1.1647149809472024]\n"
     ]
    }
   ],
   "source": [
    "vifs = [variance_inflation_factor(arr, i) for i in range(arr.shape[1])]\n",
    "print(len(vifs))\n",
    "## NOTE: any VIF > 4 needs investigation for possible multicollinearity!\n",
    "print(sorted(vifs)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9603, 21) (9603,)\n",
      "(7682, 21) (1921, 21)\n"
     ]
    }
   ],
   "source": [
    "## Split in train/test/valid\n",
    "X = arr\n",
    "y = df2['price'].to_numpy()  ## target var is UNSCALED\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2021)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.608</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.607</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   565.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 Feb 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:16:18</td>     <th>  Log-Likelihood:    </th> <td> -78796.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  7682</td>      <th>  AIC:               </th> <td>1.576e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  7660</td>      <th>  BIC:               </th> <td>1.578e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    21</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                       <td>-1.823e+06</td> <td> 4.91e+04</td> <td>  -37.164</td> <td> 0.000</td> <td>-1.92e+06</td> <td>-1.73e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numerical__year</th>             <td>  913.7979</td> <td>   24.998</td> <td>   36.555</td> <td> 0.000</td> <td>  864.795</td> <td>  962.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numerical__odometer</th>         <td>   -0.0521</td> <td>    0.002</td> <td>  -32.604</td> <td> 0.000</td> <td>   -0.055</td> <td>   -0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numerical__F1</th>               <td>    0.3169</td> <td>    0.054</td> <td>    5.827</td> <td> 0.000</td> <td>    0.210</td> <td>    0.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numerical__F2</th>               <td> -252.7499</td> <td>  786.228</td> <td>   -0.321</td> <td> 0.748</td> <td>-1793.973</td> <td> 1288.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numerical__F3</th>               <td> 1.011e+04</td> <td>  792.827</td> <td>   12.756</td> <td> 0.000</td> <td> 8559.152</td> <td> 1.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x0_subaru</th>      <td> 3061.0933</td> <td>  302.556</td> <td>   10.117</td> <td> 0.000</td> <td> 2468.000</td> <td> 3654.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x1_fair</th>        <td>-1418.3343</td> <td>  464.605</td> <td>   -3.053</td> <td> 0.002</td> <td>-2329.087</td> <td> -507.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x1_good</th>        <td> -297.1410</td> <td>  178.387</td> <td>   -1.666</td> <td> 0.096</td> <td> -646.828</td> <td>   52.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x1_like new</th>    <td> 1286.7560</td> <td>  266.482</td> <td>    4.829</td> <td> 0.000</td> <td>  764.379</td> <td> 1809.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x2_6 cylinders</th> <td> 4205.5344</td> <td>  235.085</td> <td>   17.889</td> <td> 0.000</td> <td> 3744.704</td> <td> 4666.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x2_8 cylinders</th> <td> 5567.0898</td> <td>  291.819</td> <td>   19.077</td> <td> 0.000</td> <td> 4995.044</td> <td> 6139.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x4_manual</th>      <td> 3160.7834</td> <td>  406.188</td> <td>    7.782</td> <td> 0.000</td> <td> 2364.544</td> <td> 3957.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x5_pickup</th>      <td> 6075.2469</td> <td>  265.113</td> <td>   22.916</td> <td> 0.000</td> <td> 5555.552</td> <td> 6594.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x5_sedan</th>       <td>-2833.1737</td> <td>  220.862</td> <td>  -12.828</td> <td> 0.000</td> <td>-3266.124</td> <td>-2400.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x5_truck</th>       <td> 5280.2196</td> <td>  245.088</td> <td>   21.544</td> <td> 0.000</td> <td> 4799.781</td> <td> 5760.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x6_blue</th>        <td> -675.1528</td> <td>  282.494</td> <td>   -2.390</td> <td> 0.017</td> <td>-1228.918</td> <td> -121.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x6_red</th>         <td> -149.3982</td> <td>  264.903</td> <td>   -0.564</td> <td> 0.573</td> <td> -668.680</td> <td>  369.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x6_silver</th>      <td> -873.7386</td> <td>  265.608</td> <td>   -3.290</td> <td> 0.001</td> <td>-1394.403</td> <td> -353.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x6_white</th>       <td>-1491.5732</td> <td>  225.726</td> <td>   -6.608</td> <td> 0.000</td> <td>-1934.057</td> <td>-1049.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x7_b</th>           <td>   65.3542</td> <td>  191.254</td> <td>    0.342</td> <td> 0.733</td> <td> -309.556</td> <td>  440.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>categorical__x7_c</th>           <td> -280.9212</td> <td>  194.890</td> <td>   -1.441</td> <td> 0.150</td> <td> -662.959</td> <td>  101.117</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1015.318</td> <th>  Durbin-Watson:     </th> <td>   1.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4702.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.567</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 6.661</td>  <th>  Cond. No.          </th> <td>7.89e+07</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.89e+07. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.608\n",
       "Model:                            OLS   Adj. R-squared:                  0.607\n",
       "Method:                 Least Squares   F-statistic:                     565.9\n",
       "Date:                Sat, 06 Feb 2021   Prob (F-statistic):               0.00\n",
       "Time:                        22:16:18   Log-Likelihood:                -78796.\n",
       "No. Observations:                7682   AIC:                         1.576e+05\n",
       "Df Residuals:                    7660   BIC:                         1.578e+05\n",
       "Df Model:                          21                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "const                       -1.823e+06   4.91e+04    -37.164      0.000   -1.92e+06   -1.73e+06\n",
       "numerical__year               913.7979     24.998     36.555      0.000     864.795     962.801\n",
       "numerical__odometer            -0.0521      0.002    -32.604      0.000      -0.055      -0.049\n",
       "numerical__F1                   0.3169      0.054      5.827      0.000       0.210       0.424\n",
       "numerical__F2                -252.7499    786.228     -0.321      0.748   -1793.973    1288.473\n",
       "numerical__F3                1.011e+04    792.827     12.756      0.000    8559.152    1.17e+04\n",
       "categorical__x0_subaru       3061.0933    302.556     10.117      0.000    2468.000    3654.186\n",
       "categorical__x1_fair        -1418.3343    464.605     -3.053      0.002   -2329.087    -507.582\n",
       "categorical__x1_good         -297.1410    178.387     -1.666      0.096    -646.828      52.546\n",
       "categorical__x1_like new     1286.7560    266.482      4.829      0.000     764.379    1809.133\n",
       "categorical__x2_6 cylinders  4205.5344    235.085     17.889      0.000    3744.704    4666.365\n",
       "categorical__x2_8 cylinders  5567.0898    291.819     19.077      0.000    4995.044    6139.136\n",
       "categorical__x4_manual       3160.7834    406.188      7.782      0.000    2364.544    3957.023\n",
       "categorical__x5_pickup       6075.2469    265.113     22.916      0.000    5555.552    6594.942\n",
       "categorical__x5_sedan       -2833.1737    220.862    -12.828      0.000   -3266.124   -2400.224\n",
       "categorical__x5_truck        5280.2196    245.088     21.544      0.000    4799.781    5760.658\n",
       "categorical__x6_blue         -675.1528    282.494     -2.390      0.017   -1228.918    -121.387\n",
       "categorical__x6_red          -149.3982    264.903     -0.564      0.573    -668.680     369.884\n",
       "categorical__x6_silver       -873.7386    265.608     -3.290      0.001   -1394.403    -353.074\n",
       "categorical__x6_white       -1491.5732    225.726     -6.608      0.000   -1934.057   -1049.089\n",
       "categorical__x7_b              65.3542    191.254      0.342      0.733    -309.556     440.265\n",
       "categorical__x7_c            -280.9212    194.890     -1.441      0.150    -662.959     101.117\n",
       "==============================================================================\n",
       "Omnibus:                     1015.318   Durbin-Watson:                   1.997\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4702.931\n",
       "Skew:                          -0.567   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.661   Cond. No.                     7.89e+07\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.89e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OLS Linear Reg Model - using sm\n",
    "## with UNSCALED data and dropped dummy vars\n",
    "X_train_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "# X_train_df.head()\n",
    "X0_train = sm.add_constant(X_train_df)\n",
    "model = sm.OLS(y_train, X0_train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numerical__F3                  1.011331e+04\n",
       "categorical__x5_pickup         6.075247e+03\n",
       "categorical__x2_8 cylinders    5.567090e+03\n",
       "categorical__x5_truck          5.280220e+03\n",
       "categorical__x2_6 cylinders    4.205534e+03\n",
       "categorical__x4_manual         3.160783e+03\n",
       "categorical__x0_subaru         3.061093e+03\n",
       "categorical__x1_like new       1.286756e+03\n",
       "numerical__year                9.137979e+02\n",
       "categorical__x7_b              6.535424e+01\n",
       "numerical__F1                  3.169477e-01\n",
       "numerical__odometer           -5.209295e-02\n",
       "categorical__x6_red           -1.493982e+02\n",
       "numerical__F2                 -2.527499e+02\n",
       "categorical__x7_c             -2.809212e+02\n",
       "categorical__x1_good          -2.971410e+02\n",
       "categorical__x6_blue          -6.751528e+02\n",
       "categorical__x6_silver        -8.737386e+02\n",
       "categorical__x1_fair          -1.418334e+03\n",
       "categorical__x6_white         -1.491573e+03\n",
       "categorical__x5_sedan         -2.833174e+03\n",
       "const                         -1.822998e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = model.params\n",
    "params.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict on test values\n",
    "X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "X0_test = sm.add_constant(X_test_df)\n",
    "y_pred = model.predict(X0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7243.074155721239"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get RMSE\n",
    "rmse = sm.tools.eval_measures.rmse(y_test, y_pred)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Regression for Modeling and Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9603, 29)\n"
     ]
    }
   ],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('minmaxscaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "## pipeline for Regularized Regression\n",
    "## DON'T drop any dummy vars\n",
    "## and scale the data\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"numerical\", num_pipeline, num_cols_no_price),\n",
    "    (\"categorical\", OneHotEncoder(), cat_cols)\n",
    "])\n",
    "\n",
    "arr_cleaned = full_pipeline.fit_transform(df3)\n",
    "print(arr_cleaned.shape) # After outlier removal\n",
    "feature_names = get_feature_names(full_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9603, 29) (9603,)\n",
      "(7682, 29) (1921, 29)\n"
     ]
    }
   ],
   "source": [
    "## Split in train/test/valid\n",
    "X = arr_cleaned\n",
    "y = df2['price'].to_numpy()\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2021)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot check / Compare models\n",
    "#### try diff models compare results using kfold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict of standard models to evaluate\n",
    "def define_models(models=dict()):\n",
    "    models['linear_reg'] = LinearRegression()\n",
    "    alpha = [round(x, 2) for x in np.linspace(0,1,11)]\n",
    "    for a in alpha:\n",
    "        models['lasso_reg_'+str(a)] = Lasso(alpha=a)\n",
    "        models['ridge_reg_'+str(a)] = Ridge(alpha=a)\n",
    "        models['en_reg_'+str(a)] = ElasticNet(alpha=a)\n",
    "    return models\n",
    " \n",
    "# evaluate a single model\n",
    "def evaluate_model(X, y, model, folds, metric):\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(estimator=model, X=X, y=y, scoring=metric, cv=folds, n_jobs=1)\n",
    "\treturn scores\n",
    "\n",
    "## see more metrics on sklearn docs\n",
    "## https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "## e.g. using RMSE (LOWER (i.e. more negative vals) = better fit)\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X, y, models, folds=10, metric='neg_root_mean_squared_error'):   \n",
    "    results = dict()\n",
    "    print(f\"Using {metric} metric for scores below:\\n\")\n",
    "    for name, model in models.items():\n",
    "        # scores = robust_evaluate_model(X, y, model, folds, metric)\n",
    "        scores = evaluate_model(X, y, model, folds, metric)\n",
    "        if scores is not None:\n",
    "            results[name] = scores\n",
    "            mean_score, std_score = np.mean(scores), np.std(scores)\n",
    "            print(f'{name}: Mean:{mean_score:.3f}, St.Dev:{std_score:.3f}')\n",
    "        else:\n",
    "            print(f'{name}: error')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using neg_root_mean_squared_error metric for scores below:\n",
      "\n",
      "linear_reg: Mean:-7016.673, St.Dev:153.561\n",
      "lasso_reg_0.0: Mean:-6975.212, St.Dev:167.421\n",
      "ridge_reg_0.0: Mean:-7052.890, St.Dev:214.013\n",
      "en_reg_0.0: Mean:-6975.212, St.Dev:167.421\n",
      "lasso_reg_0.1: Mean:-6975.211, St.Dev:167.421\n",
      "ridge_reg_0.1: Mean:-6975.211, St.Dev:167.371\n",
      "en_reg_0.1: Mean:-8037.064, St.Dev:187.070\n",
      "lasso_reg_0.2: Mean:-6975.206, St.Dev:167.421\n",
      "ridge_reg_0.2: Mean:-6975.212, St.Dev:167.321\n",
      "en_reg_0.2: Mean:-8662.074, St.Dev:213.231\n",
      "lasso_reg_0.3: Mean:-6975.196, St.Dev:167.424\n",
      "ridge_reg_0.3: Mean:-6975.217, St.Dev:167.271\n",
      "en_reg_0.3: Mean:-9051.750, St.Dev:228.828\n",
      "lasso_reg_0.4: Mean:-6975.183, St.Dev:167.431\n",
      "ridge_reg_0.4: Mean:-6975.224, St.Dev:167.222\n",
      "en_reg_0.4: Mean:-9320.273, St.Dev:239.068\n",
      "lasso_reg_0.5: Mean:-6975.156, St.Dev:167.441\n",
      "ridge_reg_0.5: Mean:-6975.234, St.Dev:167.173\n",
      "en_reg_0.5: Mean:-9518.029, St.Dev:246.300\n",
      "lasso_reg_0.6: Mean:-6975.138, St.Dev:167.451\n",
      "ridge_reg_0.6: Mean:-6975.247, St.Dev:167.124\n",
      "en_reg_0.6: Mean:-9670.616, St.Dev:251.684\n",
      "lasso_reg_0.7: Mean:-6975.119, St.Dev:167.456\n",
      "ridge_reg_0.7: Mean:-6975.262, St.Dev:167.075\n",
      "en_reg_0.7: Mean:-9792.481, St.Dev:255.860\n",
      "lasso_reg_0.8: Mean:-6975.098, St.Dev:167.458\n",
      "ridge_reg_0.8: Mean:-6975.281, St.Dev:167.026\n",
      "en_reg_0.8: Mean:-9892.398, St.Dev:259.193\n",
      "lasso_reg_0.9: Mean:-6975.078, St.Dev:167.459\n",
      "ridge_reg_0.9: Mean:-6975.302, St.Dev:166.978\n",
      "en_reg_0.9: Mean:-9976.040, St.Dev:261.920\n",
      "lasso_reg_1.0: Mean:-6975.059, St.Dev:167.460\n",
      "ridge_reg_1.0: Mean:-6975.325, St.Dev:166.930\n",
      "en_reg_1.0: Mean:-10047.238, St.Dev:264.196\n"
     ]
    }
   ],
   "source": [
    "models = define_models() \n",
    "results = evaluate_models(X, y, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('en_reg_1.0', -10047.238),\n",
       " ('en_reg_0.9', -9976.0398),\n",
       " ('en_reg_0.8', -9892.3975),\n",
       " ('en_reg_0.7', -9792.481),\n",
       " ('en_reg_0.6', -9670.6159),\n",
       " ('en_reg_0.5', -9518.0295),\n",
       " ('en_reg_0.4', -9320.2725),\n",
       " ('en_reg_0.3', -9051.7502),\n",
       " ('en_reg_0.2', -8662.0743),\n",
       " ('en_reg_0.1', -8037.064),\n",
       " ('ridge_reg_0.0', -7052.8904),\n",
       " ('linear_reg', -7016.6731),\n",
       " ('ridge_reg_1.0', -6975.3253),\n",
       " ('ridge_reg_0.9', -6975.3017),\n",
       " ('ridge_reg_0.8', -6975.2807),\n",
       " ('ridge_reg_0.7', -6975.2624),\n",
       " ('ridge_reg_0.6', -6975.2468),\n",
       " ('ridge_reg_0.5', -6975.234),\n",
       " ('ridge_reg_0.4', -6975.224),\n",
       " ('ridge_reg_0.3', -6975.2168),\n",
       " ('lasso_reg_0.0', -6975.2125),\n",
       " ('en_reg_0.0', -6975.2125),\n",
       " ('ridge_reg_0.2', -6975.2124),\n",
       " ('ridge_reg_0.1', -6975.211),\n",
       " ('lasso_reg_0.1', -6975.2106),\n",
       " ('lasso_reg_0.2', -6975.2056),\n",
       " ('lasso_reg_0.3', -6975.1964),\n",
       " ('lasso_reg_0.4', -6975.1833),\n",
       " ('lasso_reg_0.5', -6975.1562),\n",
       " ('lasso_reg_0.6', -6975.1382),\n",
       " ('lasso_reg_0.7', -6975.1191),\n",
       " ('lasso_reg_0.8', -6975.0982),\n",
       " ('lasso_reg_0.9', -6975.0784),\n",
       " ('lasso_reg_1.0', -6975.0589)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_results = {name: np.round(np.mean(arr), 4) for name, arr in results.items()}\n",
    "## sort results with 'best' models first (having lowest error scores)\n",
    "sorted(mean_results.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Lasso does the best at alpha=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print and plot the top n results\n",
    "def summarize_results(results, maximize=True, top_n=10):\n",
    "    # check for no results\n",
    "    if len(results) == 0:\n",
    "        print('no results')\n",
    "        return\n",
    "    # determine how many results to summarize\n",
    "    n = min(top_n, len(results))\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_scores = [(k, np.mean(v)) for k, v in results.items()]\n",
    "    # sort tuples by mean score\n",
    "    mean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "    # reverse for descending order (e.g. for accuracy)\n",
    "    if maximize:\n",
    "        mean_scores = list(reversed(mean_scores))\n",
    "    # retrieve the top n for summarization\n",
    "    names = [x[0] for x in mean_scores[:n]]\n",
    "    scores = [results[x[0]] for x in mean_scores[:n]]\n",
    "    # print the top n\n",
    "    print()\n",
    "    for i in range(n):\n",
    "        name = names[i]\n",
    "        mean_score, std_score = np.mean(results[name]), np.std(results[name])\n",
    "        print('Rank=%d, Name=%s, Score=%.3f (+/- %.3f)' %\n",
    "              (i+1, name, mean_score, std_score))\n",
    "    # boxplot for the top n\n",
    "    plt.boxplot(scores, labels=names)\n",
    "    _, labels = plt.xticks()\n",
    "    plt.setp(labels, rotation=90)\n",
    "    plt.title('Top 10 Best Regularized Regression Models')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.savefig('../images/PS_1/spotcheck_models.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rank=1, Name=lasso_reg_1.0, Score=-6975.059 (+/- 167.460)\n",
      "Rank=2, Name=lasso_reg_0.9, Score=-6975.078 (+/- 167.459)\n",
      "Rank=3, Name=lasso_reg_0.8, Score=-6975.098 (+/- 167.458)\n",
      "Rank=4, Name=lasso_reg_0.7, Score=-6975.119 (+/- 167.456)\n",
      "Rank=5, Name=lasso_reg_0.6, Score=-6975.138 (+/- 167.451)\n",
      "Rank=6, Name=lasso_reg_0.5, Score=-6975.156 (+/- 167.441)\n",
      "Rank=7, Name=lasso_reg_0.4, Score=-6975.183 (+/- 167.431)\n",
      "Rank=8, Name=lasso_reg_0.3, Score=-6975.196 (+/- 167.424)\n",
      "Rank=9, Name=lasso_reg_0.2, Score=-6975.206 (+/- 167.421)\n",
      "Rank=10, Name=lasso_reg_0.1, Score=-6975.211 (+/- 167.421)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X.shape[0]  ## sample size\n",
    "p = X.shape[1]  ## num of predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge()\n",
      "Coefficients: \n",
      " [ 33300.228052   -23184.96857779   2568.3272347     139.1360432\n",
      "   6071.53242675  -1528.36836268   1528.36836266    119.1987654\n",
      "  -1350.33911878   -190.60214299   1421.74249666  -3240.59261983\n",
      "    948.58974245   2292.00287711      0.          -1564.35348712\n",
      "   1564.35348712  -2135.4273378    3949.45700326  -4966.89722715\n",
      "   3152.86756158    639.56485171    -37.82900442    485.48437396\n",
      "   -236.365062     -850.85515919     71.86514407    136.64226909\n",
      "   -208.50741319]\n",
      "Root Mean squared error: 7241.694265383738\n",
      "MASE: 4905.842494800269\n",
      "Coefficient of determination R^2: 0.5697\n",
      "Adjusted R^2 is 0.5684\n"
     ]
    }
   ],
   "source": [
    "## EN model\n",
    "# en_reg = ElasticNet(alpha=1.0)\n",
    "# print(en_reg)\n",
    "# en_reg.fit(X_train, y_train)\n",
    "# y_pred_en = en_reg.predict(X_test)\n",
    "# print('Coefficients: \\n', en_reg.coef_)\n",
    "# print(f'Root Mean squared error: {mean_squared_error(y_test, y_pred_en, squared=False)}')\n",
    "# print(f'MASE: {mean_absolute_error(y_test, y_pred_en)}')\n",
    "# r2 = round(r2_score(y_test, y_pred_en),4)\n",
    "# print(f'Coefficient of determination R^2: {r2}')\n",
    "\n",
    "## Ridge model\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "print(ridge_reg)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "y_pred = ridge_reg.predict(X_test)\n",
    "print('Coefficients: \\n', ridge_reg.coef_)\n",
    "print(f'Root Mean squared error: {mean_squared_error(y_test, y_pred, squared=False)}')\n",
    "print(f'MASE: {mean_absolute_error(y_test, y_pred)}')\n",
    "r2 = round(r2_score(y_test, y_pred),4)\n",
    "print(f'Coefficient of determination R^2: {r2}')\n",
    "adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "print(f'Adjusted R^2 is {round(adj_r2,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso()\n",
      "Coefficients: \n",
      " [ 3.36106479e+04 -2.32755136e+04  2.50170472e+03 -5.91178717e+01\n",
      "  6.06742944e+03 -3.04748344e+03  0.00000000e+00  1.52005574e-01\n",
      " -1.39686171e+03 -2.93972146e+02  1.28119062e+03 -4.74619732e+03\n",
      " -5.43149969e+02  8.11238854e+02  0.00000000e+00 -3.13266713e+03\n",
      "  1.13896837e-11 -2.61411761e+03  3.45572691e+03 -5.44544643e+03\n",
      "  2.65910917e+03  6.68781225e+02  0.00000000e+00  5.19210756e+02\n",
      " -1.94302819e+02 -8.13166062e+02  0.00000000e+00  6.26865119e+01\n",
      " -2.77371226e+02]\n",
      "Root Mean squared error: 7242.720354480176\n",
      "Coefficient of determination R^2: 0.5695\n",
      "Adjusted R^2 is 0.5682\n"
     ]
    }
   ],
   "source": [
    "# Lasso model\n",
    "lasso_reg = Lasso(alpha=1.0)\n",
    "print(lasso_reg)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_reg.predict(X_test)\n",
    "print('Coefficients: \\n', lasso_reg.coef_)\n",
    "print(f'Root Mean squared error: {mean_squared_error(y_test, y_pred_lasso, squared=False)}')\n",
    "r2 = round(r2_score(y_test, y_pred_lasso) ,4)\n",
    "print(f'Coefficient of determination R^2: {r2}')\n",
    "adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "print(f'Adjusted R^2 is {round(adj_r2,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion of results\n",
    "Using the UNSCALED data with first dummy variables dropped, the OLS Lin Reg model had the highest Adj R^2 value at ~0.6\n",
    "\n",
    "But using the SCALED data without any dummy variables dropped, the 'best' regularized model (chosen using kfold CV) had lowest RMSE and slightly lower Adj R^2 compared to OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: BEFORE SUBMITTING CODE: \n",
    "### remember to remove all comments, change code structure so you didn't copy anyone\n",
    "\n",
    "### add HO ML book and ml mastery website to citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
